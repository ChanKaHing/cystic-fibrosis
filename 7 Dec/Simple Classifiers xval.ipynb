{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "6af420d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from correlation_map import corr_map\n",
    "from correlation_3D import corr_3D, rat_bead_study_data, rat_pa_study_data, mouse_b_enac_study_data, mouse_mps_study_data\n",
    "from Principle_Component_Analysis import pca_2D, pca_3D\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "076bf675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mouse_b_enac = pd.read_csv('mouse_b_enac_summary.csv')\n",
    "df_mouse_enac_combine, b_enac_labels = mouse_b_enac_study_data(df_mouse_b_enac)\n",
    "\n",
    "df_mouse_mps = pd.read_csv('mouse_mps_summary.csv')\n",
    "df_mouse_mps_combine, mps_labels = mouse_mps_study_data(df_mouse_mps)\n",
    "\n",
    "df_mouse_enac_combine_sel = df_mouse_enac_combine[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','Genotype','IQR','HD']]\n",
    "df_mouse_mps_combine_sel = df_mouse_mps_combine[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','Genotype','IQR','HD']]\n",
    "df_mouse_all = pd.concat([df_mouse_enac_combine_sel, df_mouse_mps_combine_sel], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a6098588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, test_size, val_size):\n",
    "    np_df = df.values\n",
    "\n",
    "    bigtrain_set, test_set = train_test_split(np_df, test_size=test_size, random_state=42, stratify=np_df[:,-1])\n",
    "    train_set, val_set = train_test_split(bigtrain_set, test_size=val_size, random_state=42, stratify=bigtrain_set[:,-1])\n",
    "\n",
    "    # Get the X and y for train, val and test\n",
    "    X_train = train_set[:,:-1]\n",
    "    y_train = train_set[:,-1]\n",
    "    X_test = test_set[:,:-1]\n",
    "    y_test = test_set[:,-1]\n",
    "    X_val = val_set[:,:-1]\n",
    "    y_val = val_set[:,-1]\n",
    "    X_bigtrain = bigtrain_set[:,:-1]\n",
    "    y_bigtrain = bigtrain_set[:,-1]\n",
    "    \n",
    "    print(f'Shapes are {[X_train.shape,y_train.shape,X_val.shape,y_val.shape,X_bigtrain.shape,y_bigtrain.shape,X_test.shape,y_test.shape]}')\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "96fbcabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM classifier and optimize the hyperparameters\n",
    "def svm_hyper_tune(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                        ('std_scaler', StandardScaler())])\n",
    "    \n",
    "    for kerneltype in ['rbf','linear','poly']:\n",
    "        for c_choice in [1, 10, 100]:\n",
    "            svm_pl = Pipeline([('preproc',preproc_pl),\n",
    "                               ('svc',SVC(kernel=kerneltype, C=c_choice, random_state=42))])\n",
    "            svm_pl.fit(X_train,y_train)\n",
    "            y_pred_svm = svm_pl.predict(X_val)\n",
    "            acc = accuracy_score(y_val,y_pred_svm)\n",
    "            print(f'Validation accuracy score = {acc} for kernel {kerneltype} and C={c_choice}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "b54bbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rat bead study (baseline vs post beads)\n",
    "def svm(X_bigtrain,y_bigtrain,X_test,y_test,name,kernel,c):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                        ('std_scaler', StandardScaler())])\n",
    "    \n",
    "    svm_pl = Pipeline([('preproc',preproc_pl),\n",
    "                       ('svc',SVC(kernel=kernel, C=c, random_state=42))])\n",
    "    \n",
    "    svm_pl.fit(X_bigtrain,y_bigtrain)\n",
    "\n",
    "    y_train_pred_svm = svm_pl.predict(X_bigtrain)\n",
    "    y_test_pred_svm = svm_pl.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_bigtrain,y_train_pred_svm)\n",
    "    acc_test = accuracy_score(y_test,y_test_pred_svm)\n",
    "    \n",
    "    print('\\033[1m' + name + '\\033[0m')\n",
    "    print()\n",
    "    print(f'Training accuracy score = {acc_train}')\n",
    "    print(f'Testing accuracy score = {acc_test}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "68b77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_hyper_tune(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "    \n",
    "    for criterion in ['gini', 'entropy']:\n",
    "        for max_depth in [5, 15, 20]:\n",
    "            dt_pl = Pipeline([('preproc',preproc_pl),\n",
    "                              ('dt', DecisionTreeClassifier(criterion=criterion,\n",
    "                                                            max_depth=max_depth, random_state=42))])\n",
    "            dt_pl.fit(X_train,y_train)\n",
    "            y_pred_dt = dt_pl.predict(X_val)\n",
    "            acc = accuracy_score(y_val,y_pred_dt)\n",
    "            print(f'Validation accuracy score = {acc} for criterion {criterion} and max_depth = {max_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bd0f8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_bigtrain,y_bigtrain,X_test,y_test,name,criterion,max_depth):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                        ('std_scaler', StandardScaler())]) \n",
    "    \n",
    "    dt_pl = Pipeline([('preproc',preproc_pl), ('dt', DecisionTreeClassifier(criterion=criterion,\n",
    "                                                            max_depth=max_depth, random_state=42))])\n",
    "    dt_pl.fit(X_bigtrain,y_bigtrain)\n",
    "\n",
    "    y_train_pred_dt = dt_pl.predict(X_bigtrain)\n",
    "    y_test_pred_dt = dt_pl.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_bigtrain,y_train_pred_dt)\n",
    "    acc_test = accuracy_score(y_test,y_test_pred_dt)\n",
    "    \n",
    "    print('\\033[1m' + name + '\\033[0m')\n",
    "    print()\n",
    "    print(f'Training accuracy score = {acc_train}')\n",
    "    print(f'Testing accuracy score = {acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4c434698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_hyper_tune(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "    for n_neighbors in [3, 5, 7, 9, 11]:\n",
    "        for weights in ['uniform', 'distance']:\n",
    "            knn_pl = Pipeline([('preproc',preproc_pl),\n",
    "                               ('knn', KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights))])\n",
    "            knn_pl.fit(X_train,y_train)\n",
    "            y_pred_knn = knn_pl.predict(X_val)\n",
    "            acc = accuracy_score(y_val,y_pred_knn)\n",
    "            print(f'Validation recall score = {acc} for n_neighbors = {n_neighbors} and weights {weights}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8bec651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_bigtrain,y_bigtrain,X_test,y_test,name,n_neighbors,weights):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    knn_pl = Pipeline([('preproc',preproc_pl), ('knn', KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "                                                                            weights=weights))])\n",
    "                                                                    \n",
    "    knn_pl.fit(X_bigtrain,y_bigtrain)\n",
    "\n",
    "    y_train_pred_knn = knn_pl.predict(X_bigtrain)\n",
    "    y_test_pred_knn = knn_pl.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_bigtrain,y_train_pred_knn)\n",
    "    acc_test = accuracy_score(y_test,y_test_pred_knn)\n",
    "    \n",
    "    print('\\033[1m' + name + '\\033[0m')\n",
    "    print()\n",
    "    print(f'Training accuracy score = {acc_train}')\n",
    "    print(f'Testing accuracy score = {acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b607bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_hyper_tune(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "    for criterion in ['gini', 'entropy']:\n",
    "        for max_depth in [5, 15, 20]:\n",
    "            rf_pl = Pipeline([('preproc',preproc_pl),\n",
    "                               ('rf', RandomForestClassifier(n_estimators=100, criterion=criterion,\n",
    "                                                            max_depth=max_depth, random_state=42))])\n",
    "            rf_pl.fit(X_train,y_train)\n",
    "            y_pred_rf = rf_pl.predict(X_val)\n",
    "            acc = accuracy_score(y_val,y_pred_rf)\n",
    "            print(f'Validation recall score = {acc} for criterion = {criterion} and max_depth {max_depth}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "064e1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_bigtrain,y_bigtrain,X_test,y_test,name,criterion,max_depth):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    rf_pl = Pipeline([('preproc',preproc_pl),\n",
    "                        ('rf', RandomForestClassifier(n_estimators=100, criterion=criterion,\n",
    "                                                        max_depth=max_depth, random_state=42))])\n",
    "                                                                    \n",
    "    rf_pl.fit(X_bigtrain,y_bigtrain)\n",
    "\n",
    "    y_train_pred_rf = rf_pl.predict(X_bigtrain)\n",
    "    y_test_pred_rf = rf_pl.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_bigtrain,y_train_pred_rf)\n",
    "    acc_test = accuracy_score(y_test,y_test_pred_rf)\n",
    "    \n",
    "    print('\\033[1m' + name + '\\033[0m')\n",
    "    print()\n",
    "    print(f'Training accuracy score = {acc_train}')\n",
    "    print(f'Testing accuracy score = {acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a69eac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbc_hyper_tune(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "    for max_depth in [3, 5, 7, 9, 11]:\n",
    "        for learning_rate in [0.01, 0.1, 1]:      \n",
    "            gbc_pl = Pipeline([('preproc',preproc_pl),\n",
    "                               ('gbc', GradientBoostingClassifier(n_estimators=100, max_depth=3, \n",
    "                                          learning_rate=learning_rate, random_state=42))])\n",
    "            gbc_pl.fit(X_train,y_train)\n",
    "            y_pred_gbc = gbc_pl.predict(X_val)\n",
    "            acc = accuracy_score(y_val,y_pred_gbc)\n",
    "            print(f'Validation recall score = {acc} for max_depth = {max_depth} and learning_rate {learning_rate}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "94d556e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbc(X_bigtrain,y_bigtrain,X_test,y_test,name,max_depth,learning_rate):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    gbc_pl = Pipeline([('preproc',preproc_pl),\n",
    "                                   ('gbc', GradientBoostingClassifier(n_estimators=100, max_depth=max_depth, \n",
    "                                          learning_rate=learning_rate, random_state=42))])\n",
    "                                                                    \n",
    "    gbc_pl.fit(X_bigtrain,y_bigtrain)\n",
    "\n",
    "    y_train_pred_gbc = gbc_pl.predict(X_bigtrain)\n",
    "    y_test_pred_gbc = gbc_pl.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_bigtrain,y_train_pred_gbc)\n",
    "    acc_test = accuracy_score(y_test,y_test_pred_gbc)\n",
    "    \n",
    "    print('\\033[1m' + name + '\\033[0m')\n",
    "    print()\n",
    "    print(f'Training accuracy score = {acc_train}')\n",
    "    print(f'Testing accuracy score = {acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0f6b2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_hyper_tune(X_train, y_train, X_val, y_val):\n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "\n",
    "    for loss in ['hinge','squared_hinge','perceptron']:\n",
    "        for penalty in ['l2', 'l1', 'elasticnet']:\n",
    "            sgd_pl = Pipeline([('preproc',preproc_pl),\n",
    "                               ('sgd',SGDClassifier(loss=loss, penalty=penalty, random_state=42))])\n",
    "            sgd_pl.fit(X_train,y_train)\n",
    "            y_pred_sgd = sgd_pl.predict(X_val)\n",
    "            acc = accuracy_score(y_val,y_pred_sgd)\n",
    "            print(f'Validation recall score = {acc} for loss {loss} and penalty {penalty}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "5e4734e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X_bigtrain,y_bigtrain,X_test,y_test,name,loss,penalty):\n",
    "    \n",
    "    preproc_pl = Pipeline([ ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('std_scaler', StandardScaler())])\n",
    "    \n",
    "    sgd_pl = Pipeline([('preproc',preproc_pl),\n",
    "                        ('sgd',SGDClassifier(loss=loss, penalty=penalty, random_state=42))])\n",
    "    sgd_pl.fit(X_bigtrain,y_bigtrain)\n",
    "    \n",
    "    y_train_pred_sgd = sgd_pl.predict(X_bigtrain)\n",
    "    y_test_pred_sgd = sgd_pl.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_bigtrain,y_train_pred_sgd)\n",
    "    acc_test = accuracy_score(y_test,y_test_pred_sgd)\n",
    "    \n",
    "    print('\\033[1m' + name + '\\033[0m')\n",
    "    print()\n",
    "    print(f'Training accuracy score = {acc_train}')\n",
    "    print(f'Testing accuracy score = {acc_test}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692a0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c909e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd4fb7d8",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "c5d5fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are [(33, 7), (33,), (12, 7), (12,), (45, 7), (45,), (16, 7), (16,)]\n",
      "\n",
      "Validation accuracy score = 0.6666666666666666 for kernel rbf and C=1\n",
      "Validation accuracy score = 0.75 for kernel rbf and C=10\n",
      "Validation accuracy score = 0.5 for kernel rbf and C=100\n",
      "Validation accuracy score = 0.75 for kernel linear and C=1\n",
      "Validation accuracy score = 0.8333333333333334 for kernel linear and C=10\n",
      "Validation accuracy score = 0.75 for kernel linear and C=100\n",
      "Validation accuracy score = 0.75 for kernel poly and C=1\n",
      "Validation accuracy score = 0.75 for kernel poly and C=10\n",
      "Validation accuracy score = 0.8333333333333334 for kernel poly and C=100\n"
     ]
    }
   ],
   "source": [
    "df_mouse_features = df_mouse_all[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','HD','Genotype']]\n",
    "X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain = data_split(df_mouse_features, 0.25, 0.25)\n",
    "print()\n",
    "svm_hyper_tune(X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "6e8d6194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMouse all\u001b[0m\n",
      "\n",
      "Training accuracy score = 0.9333333333333333\n",
      "Testing accuracy score = 0.75\n"
     ]
    }
   ],
   "source": [
    "svm(X_bigtrain,y_bigtrain,X_test,y_test,'Mouse all','linear',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "dd8eff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are [(33, 7), (33,), (12, 7), (12,), (45, 7), (45,), (16, 7), (16,)]\n",
      "\n",
      "Validation accuracy score = 0.75 for criterion gini and max_depth = 5\n",
      "Validation accuracy score = 0.75 for criterion gini and max_depth = 15\n",
      "Validation accuracy score = 0.75 for criterion gini and max_depth = 20\n",
      "Validation accuracy score = 0.6666666666666666 for criterion entropy and max_depth = 5\n",
      "Validation accuracy score = 0.6666666666666666 for criterion entropy and max_depth = 15\n",
      "Validation accuracy score = 0.6666666666666666 for criterion entropy and max_depth = 20\n"
     ]
    }
   ],
   "source": [
    "df_mouse_features = df_mouse_all[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','HD','Genotype']]\n",
    "X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain = data_split(df_mouse_features, 0.25, 0.25)\n",
    "print()\n",
    "decision_tree_hyper_tune(X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "66bfb0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMouse all\u001b[0m\n",
      "\n",
      "Training accuracy score = 1.0\n",
      "Testing accuracy score = 0.75\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_bigtrain,y_bigtrain,X_test,y_test,'Mouse all','gini',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b47fd8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are [(33, 7), (33,), (12, 7), (12,), (45, 7), (45,), (16, 7), (16,)]\n",
      "\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 3 and weights uniform\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 3 and weights distance\n",
      "Validation recall score = 0.75 for n_neighbors = 5 and weights uniform\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 5 and weights distance\n",
      "Validation recall score = 0.75 for n_neighbors = 7 and weights uniform\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 7 and weights distance\n",
      "Validation recall score = 0.75 for n_neighbors = 9 and weights uniform\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 9 and weights distance\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 11 and weights uniform\n",
      "Validation recall score = 0.6666666666666666 for n_neighbors = 11 and weights distance\n"
     ]
    }
   ],
   "source": [
    "df_mouse_features = df_mouse_all[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','HD','Genotype']]\n",
    "X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain = data_split(df_mouse_features, 0.25, 0.25)\n",
    "print()\n",
    "knn_hyper_tune(X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d8462e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMouse all\u001b[0m\n",
      "\n",
      "Training accuracy score = 0.8\n",
      "Testing accuracy score = 0.6875\n"
     ]
    }
   ],
   "source": [
    "knn(X_bigtrain,y_bigtrain,X_test,y_test,'Mouse all',5,'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4cc0868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are [(33, 7), (33,), (12, 7), (12,), (45, 7), (45,), (16, 7), (16,)]\n",
      "\n",
      "Validation recall score = 0.75 for criterion = gini and max_depth 5\n",
      "Validation recall score = 0.75 for criterion = gini and max_depth 15\n",
      "Validation recall score = 0.75 for criterion = gini and max_depth 20\n",
      "Validation recall score = 0.75 for criterion = entropy and max_depth 5\n",
      "Validation recall score = 0.75 for criterion = entropy and max_depth 15\n",
      "Validation recall score = 0.75 for criterion = entropy and max_depth 20\n"
     ]
    }
   ],
   "source": [
    "df_mouse_features = df_mouse_all[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','HD','Genotype']]\n",
    "X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain = data_split(df_mouse_features, 0.25, 0.25)\n",
    "print()\n",
    "rf_hyper_tune(X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "124086da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMouse all\u001b[0m\n",
      "\n",
      "Training accuracy score = 1.0\n",
      "Testing accuracy score = 0.625\n"
     ]
    }
   ],
   "source": [
    "rf(X_bigtrain,y_bigtrain,X_test,y_test,'Mouse all','gini',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "b5a2289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are [(33, 7), (33,), (12, 7), (12,), (45, 7), (45,), (16, 7), (16,)]\n",
      "\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 3 and learning_rate 0.01\n",
      "Validation recall score = 0.75 for max_depth = 3 and learning_rate 0.1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 3 and learning_rate 1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 5 and learning_rate 0.01\n",
      "Validation recall score = 0.75 for max_depth = 5 and learning_rate 0.1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 5 and learning_rate 1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 7 and learning_rate 0.01\n",
      "Validation recall score = 0.75 for max_depth = 7 and learning_rate 0.1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 7 and learning_rate 1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 9 and learning_rate 0.01\n",
      "Validation recall score = 0.75 for max_depth = 9 and learning_rate 0.1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 9 and learning_rate 1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 11 and learning_rate 0.01\n",
      "Validation recall score = 0.75 for max_depth = 11 and learning_rate 0.1\n",
      "Validation recall score = 0.6666666666666666 for max_depth = 11 and learning_rate 1\n"
     ]
    }
   ],
   "source": [
    "df_mouse_features = df_mouse_all[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','HD','Genotype']]\n",
    "X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain = data_split(df_mouse_features, 0.25, 0.25)\n",
    "print()\n",
    "gbc_hyper_tune(X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7b2e6218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMouse all\u001b[0m\n",
      "\n",
      "Training accuracy score = 1.0\n",
      "Testing accuracy score = 0.75\n"
     ]
    }
   ],
   "source": [
    "gbc(X_bigtrain,y_bigtrain,X_test,y_test,'Mouse all',11,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "90701d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are [(33, 7), (33,), (12, 7), (12,), (45, 7), (45,), (16, 7), (16,)]\n",
      "\n",
      "Validation recall score = 0.8333333333333334 for loss hinge and penalty l2\n",
      "Validation recall score = 0.9166666666666666 for loss hinge and penalty l1\n",
      "Validation recall score = 0.8333333333333334 for loss hinge and penalty elasticnet\n",
      "Validation recall score = 0.5833333333333334 for loss squared_hinge and penalty l2\n",
      "Validation recall score = 0.8333333333333334 for loss squared_hinge and penalty l1\n",
      "Validation recall score = 0.5833333333333334 for loss squared_hinge and penalty elasticnet\n",
      "Validation recall score = 0.8333333333333334 for loss perceptron and penalty l2\n",
      "Validation recall score = 0.9166666666666666 for loss perceptron and penalty l1\n",
      "Validation recall score = 0.5833333333333334 for loss perceptron and penalty elasticnet\n"
     ]
    }
   ],
   "source": [
    "df_mouse_features = df_mouse_all[['VDP(%)','MSV(mL/mL)','TV(L)','VH(%)','VHSS(%)','VHLS(%)','HD','Genotype']]\n",
    "X_train,y_train,X_test,y_test,X_val,y_val,X_bigtrain,y_bigtrain = data_split(df_mouse_features, 0.25, 0.25)\n",
    "print()\n",
    "sgd_hyper_tune(X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "8fd83d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMouse all\u001b[0m\n",
      "\n",
      "Training accuracy score = 0.8\n",
      "Testing accuracy score = 0.75\n"
     ]
    }
   ],
   "source": [
    "sgd(X_bigtrain,y_bigtrain,X_test,y_test,'Mouse all','hinge','l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e755f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
